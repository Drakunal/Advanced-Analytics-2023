{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef114a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76f77ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"@xyzzz I am sad today ðŸ˜” http://twitter.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a3f66",
   "metadata": {},
   "source": [
    "@something -> @user\n",
    "\n",
    "\n",
    "http://twitter.com -> http"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c5c5f",
   "metadata": {},
   "source": [
    "Final should look like this -> \"@user It is so hot today! ðŸ˜” http\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8a088d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for word in text.split(\" \"):\n",
    "        word = '@user' if word.startswith('@') and len(word) > 1 else word\n",
    "        word = 'http' if word.startswith('http') else word\n",
    "        new_text.append(word)\n",
    "    print(new_text)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a22b9de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@user', 'I', 'am', 'sad', 'today', 'ðŸ˜”', 'http']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'@user I am sad today ðŸ˜” http'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_preprocessed = preprocess(tweet)\n",
    "tweet_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c675056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and tokenizer\n",
    "roberta = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4234bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Negative','Neutral','Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b4911c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = tokenizer(tweet_preprocessed, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8262927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  1039, 12105,    38,   524,  5074,   452, 17841, 10674,  2054,\n",
       "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "055f3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(tokenized_tweet['input_ids'],tokenized_tweet['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4ca9416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 2.5438, -0.1424, -2.3125]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shortcut\n",
    "output = model(**tokenized_tweet)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8e17bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = output[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8685c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5438228 , -0.14241631, -2.3125308 ], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cda3dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30d95f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92944103, 0.06332906, 0.00722993], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2db85206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative 0.92944103\n",
      "Neutral 0.06332906\n",
      "Positive 0.007229932\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scores)):\n",
    "    l = labels[i]\n",
    "    s = scores[i]\n",
    "    print(l,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03d81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
